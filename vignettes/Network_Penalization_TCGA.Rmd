---
title: "Network regularization on TCGA Cancer Data"
author: "André Veríssimo"
date: "`r Sys.Date()`"
output:
  #rmarkdown::html_vignette:
  html_document:
    toc: true
    self_contained: true
    number_sections: true
    fig_width: 10
#vignette: >
#  %\VignetteIndexEntry{Vignette Title}
#  %\VignetteEngine{knitr::rmarkdown}
#  %\VignetteEncoding{UTF-8}
params:
  project: 'prad' # skcm prad brca
  tissue: 'primary.solid.tumor' # primary.solid.tumor metastatic solid.tissue.normal
  coding.genes: !r TRUE
  degree.unweighted: !r TRUE
  degree.correlation: 'pearson'
  degree.cutoff: !r 0
  #
  degree.type: "string" # covariance, correlation, correlation.inv, oldie, sparsebn, string
  #
  handle.duplicates: 'keep_first' # keep_all , keep_first
  #
  # glmnet parameter
  alpha: !r .7
  # subset of variables to be used (Inf for all)
  subset: !r Inf
  train: !r .8
  # number of times that training set is tested
  ntimes: !r 10
  # target variables that models should output
  target.vars: !r list(classic.cv = 28, degree.cv = 42, orphan.cv = 70)
  #
  seed: !r 1985
  mc.cores: !r 1
  #
  calc.params.old: !r FALSE
---



```{r setup, include=FALSE}
# ComBat(matrix and category_id)
# plotMDS(matrix and some color stuff)
# inSilicoDB is good to understand that and validate results
knitr::opts_chunk$set(echo = TRUE, collapse = TRUE, tidy = TRUE)
library(futile.logger)
library(parallel)
library(glmnet)
library(loose.rock)
library(digest)
library(ggplot2)
library(reshape2)
library(survival)
library(brca.data)
library(Vennerable)
library(limma)
library(tidyverse)
library(forcats)
library(survival.owl)
library(biclust)
devtools::load_all()
#
.Last.value <- base.dir(path = '/ssd_home/averissimo/work/rpackages/network.cox-cache')
.Last.value <- show.message(FALSE)
.Last.value <- flog.layout(layout.format('[~l] ~m'))
.Last.value <- flog.appender(appender.tee('logger.txt'))
theme_set(theme_minimal())
```

```{r, eval=FALSE, include=FALSE}
run.me <- function(my.params) {
  dir.create('reports', showWarnings = F)
  rmarkdown::render('Network_Penalization_TCGA.Rmd',
                    output_file = sprintf('./reports/project-%s__train-%.2f__alpha-%.2f__cutoff-%.4f__type-%s__unw-%s.html', 
                                          my.params$project,
                                          my.params$train,
                                          my.params$alpha,
                                          my.params$degree.cutoff,
                                          my.params$degree.type,
                                          my.params$degree.unweighted),
                    params = my.params)
}

my.list <-list(
  #
  # Covariance
  #
  # binary network
  #
  #list(alpha = 1.0, degree.cutoff = 0, degree.type = 'string',  degree.unweighted = TRUE, project = 'brca', train = 1),
  #list(alpha = 0.5, degree.cutoff = 0, degree.type = 'string',  degree.unweighted = TRUE, project = 'brca', train = 1),
  #list(alpha = 0.7, degree.cutoff = 0, degree.type = 'string',  degree.unweighted = TRUE, project = 'brca', train = 1),
  list(alpha = 1.0, degree.cutoff = 0, degree.type = 'string',  degree.unweighted = TRUE, project = 'brca', train = 0.8),
  list(alpha = 0.5, degree.cutoff = 0, degree.type = 'string',  degree.unweighted = TRUE, project = 'brca', train = 0.8),
  list(alpha = 0.7, degree.cutoff = 0, degree.type = 'string',  degree.unweighted = TRUE, project = 'brca', train = 0.8),
  #list(alpha = 1.0, degree.cutoff = 0, degree.type = 'string',  degree.unweighted = TRUE, project = 'brca', train = 0.9),
  #list(alpha = 0.5, degree.cutoff = 0, degree.type = 'string',  degree.unweighted = TRUE, project = 'brca', train = 0.9),
  #list(alpha = 0.7, degree.cutoff = 0, degree.type = 'string',  degree.unweighted = TRUE, project = 'brca', train = 0.9),
  #
  #
  # PROBLEM!!
  #list(alpha = 1.0, degree.cutoff = 0, degree.type = 'string',  degree.unweighted = TRUE, project = 'prad', train = 1),
  #list(alpha = 0.5, degree.cutoff = 0, degree.type = 'string',  degree.unweighted = TRUE, project = 'prad', train = 1),
  #list(alpha = 0.7, degree.cutoff = 0, degree.type = 'string',  degree.unweighted = TRUE, project = 'prad', train = 1),
  #list(alpha = 1.0, degree.cutoff = 0, degree.type = 'string',  degree.unweighted = TRUE, project = 'prad', train = 0.8),
  #list(alpha = 0.5, degree.cutoff = 0, degree.type = 'string',  degree.unweighted = TRUE, project = 'prad', train = 0.8),
  #list(alpha = 0.7, degree.cutoff = 0, degree.type = 'string',  degree.unweighted = TRUE, project = 'prad', train = 0.8),
  #list(alpha = 1.0, degree.cutoff = 0, degree.type = 'string',  degree.unweighted = TRUE, project = 'prad', train = 0.9),
  #list(alpha = 0.5, degree.cutoff = 0, degree.type = 'string',  degree.unweighted = TRUE, project = 'prad', train = 0.9),
  #list(alpha = 0.7, degree.cutoff = 0, degree.type = 'string',  degree.unweighted = TRUE, project = 'prad', train = 0.9),
  #
  #
  #list(alpha = 1.0, degree.cutoff = 0, degree.type = 'string',  degree.unweighted = TRUE, project = 'skcm', train = 1),
  #list(alpha = 0.5, degree.cutoff = 0, degree.type = 'string',  degree.unweighted = TRUE, project = 'skcm', train = 1),
  #list(alpha = 0.7, degree.cutoff = 0, degree.type = 'string',  degree.unweighted = TRUE, project = 'skcm', train = 1),
  #list(alpha = 1.0, degree.cutoff = 0, degree.type = 'string',  degree.unweighted = TRUE, project = 'skcm', train = 0.8),
  #list(alpha = 0.5, degree.cutoff = 0, degree.type = 'string',  degree.unweighted = TRUE, project = 'skcm', train = 0.8),
  #list(alpha = 0.7, degree.cutoff = 0, degree.type = 'string',  degree.unweighted = TRUE, project = 'skcm', train = 0.8),
  list(alpha = 1.0, degree.cutoff = 0, degree.type = 'string',  degree.unweighted = TRUE, project = 'skcm', train = 0.9),
  list(alpha = 0.5, degree.cutoff = 0, degree.type = 'string',  degree.unweighted = TRUE, project = 'skcm', train = 0.9),
  list(alpha = 0.7, degree.cutoff = 0, degree.type = 'string',  degree.unweighted = TRUE, project = 'skcm', train = 0.9),
  list(end = T)
  )

library(parallel)
library(foreach)
library(doParallel)

#cl<-makeCluster(3)
#registerDoParallel(cl)

#foreach(ix = my.list, .combine = c) %dopar% {
for (ix in my.list) {
 if (is.null(ix[['end']]) || !ix[['end']]) {
   run.me(ix)
 }
 NULL
}

#stopCluster(cl)
```


```{r, eval=FALSE, include=FALSE}
run.me <- function(my.params) {
  rmarkdown::render('Network_Penalization_TCGA.Rmd',
                    output_file = sprintf('alpha-%.2f__cutoff-%.4f__type-%s__unw-%s.html', 
                                          my.params$alpha,
                                          my.params$degree.cutoff,
                                          my.params$degree.type,
                                          my.params$degree.unweighted),
                    params = my.params)
}

(env.spa <- new.env()) %>% load('../saves/quantile.abs-sparsebn.RData', envir = .)
(env.cor <- new.env()) %>% load('../saves/quantile.abs-correlation.RData', envir = .)
(env.cov <- new.env()) %>% load('../saves/quantile.abs-covariance.RData', envir = .)

cor.spa <- env.spa$result
cor.cor <- env.cor$result
cor.cov <- env.cov$result

my.list <-list(
  #
  # Covariance
  #
  # binary network
  list(alpha = 1.0, degree.cutoff = cor.cov['99.99%'], degree.type = 'covariance',  degree.unweighted = TRUE),
  list(alpha = 0.5, degree.cutoff = cor.cov['99.99%'], degree.type = 'covariance',  degree.unweighted = TRUE),
  list(alpha = 0.0, degree.cutoff = cor.cov['99.99%'], degree.type = 'covariance',  degree.unweighted = TRUE),
  #
  # using weights
  list(alpha = 1.0, degree.cutoff = cor.cov['99.99%'], degree.type = 'covariance',  degree.unweighted = FALSE),
  list(alpha = 0.5, degree.cutoff = cor.cov['99.99%'], degree.type = 'covariance',  degree.unweighted = FALSE),
  list(alpha = 0.0, degree.cutoff = cor.cov['99.99%'], degree.type = 'covariance',  degree.unweighted = FALSE),
  #
  # Correlation
  #
  # binary network
  list(alpha = 0.5, degree.cutoff = cor.cor['99.99%'],  degree.type = 'correlation', degree.unweighted = TRUE),
  list(alpha = 1.0, degree.cutoff = cor.cor['99.99%'],  degree.type = 'correlation', degree.unweighted = TRUE),
  list(alpha = 0.0, degree.cutoff = cor.cor['99.99%'],  degree.type = 'correlation', degree.unweighted = TRUE),
  list(alpha = 0.5, degree.cutoff = cor.cor['99%'],     degree.type = 'correlation', degree.unweighted = TRUE),
  list(alpha = 1.0, degree.cutoff = cor.cor['99%'],     degree.type = 'correlation', degree.unweighted = TRUE),
  list(alpha = 0.0, degree.cutoff = cor.cor['99%'],     degree.type = 'correlation', degree.unweighted = TRUE),
  # using weights
  list(alpha = 0.5, degree.cutoff = cor.cor['99.99%'],  degree.type = 'correlation', degree.unweighted = FALSE),
  list(alpha = 1.0, degree.cutoff = cor.cor['99.99%'],  degree.type = 'correlation', degree.unweighted = FALSE),
  list(alpha = 0.0, degree.cutoff = cor.cor['99.99%'],  degree.type = 'correlation', degree.unweighted = FALSE),
  list(alpha = 0.5, degree.cutoff = cor.cor['99%'],     degree.type = 'correlation', degree.unweighted = FALSE),
  list(alpha = 1.0, degree.cutoff = cor.cor['99%'],     degree.type = 'correlation', degree.unweighted = FALSE),
  list(alpha = 0.0, degree.cutoff = cor.cor['99%'],     degree.type = 'correlation', degree.unweighted = FALSE),
  #
  # STRING (Pedro Martinho)
  # 
  # binary network
  list(alpha = 0.5, degree.cutoff = 0, degree.type = 'string', degree.unweighted = TRUE),
  list(alpha = 1.0, degree.cutoff = 0, degree.type = 'string', degree.unweighted = TRUE),
  list(alpha = 0.0, degree.cutoff = 0, degree.type = 'string', degree.unweighted = TRUE),
  # using weights
  list(alpha = 0.5, degree.cutoff = 0, degree.type = 'string', degree.unweighted = FALSE),
  list(alpha = 1.0, degree.cutoff = 0, degree.type = 'string', degree.unweighted = FALSE),
  list(alpha = 0.0, degree.cutoff = 0, degree.type = 'string', degree.unweighted = FALSE),
  #
  # SparseBN (João Brito)
  #
  # binary network
  list(alpha = 0.5, degree.cutoff = 0,              degree.type = 'sparsebn', degree.unweighted = TRUE),
  list(alpha = 1.0, degree.cutoff = 0,              degree.type = 'sparsebn', degree.unweighted = TRUE),
  list(alpha = 0.0, degree.cutoff = 0,              degree.type = 'sparsebn', degree.unweighted = TRUE),
  list(alpha = 0.5, degree.cutoff = cor.spa['99%'], degree.type = 'sparsebn', degree.unweighted = TRUE),
  list(alpha = 1.0, degree.cutoff = cor.spa['99%'], degree.type = 'sparsebn', degree.unweighted = TRUE),
  list(alpha = 0.0, degree.cutoff = cor.spa['99%'], degree.type = 'sparsebn', degree.unweighted = TRUE),
  # 
  list(alpha = 0.5, degree.cutoff = 0,              degree.type = 'sparsebn', degree.unweighted = FALSE),
  list(alpha = 1.0, degree.cutoff = 0,              degree.type = 'sparsebn', degree.unweighted = FALSE),
  list(alpha = 0.0, degree.cutoff = 0,              degree.type = 'sparsebn', degree.unweighted = FALSE),
  list(alpha = 0.5, degree.cutoff = cor.spa['99%'], degree.type = 'sparsebn', degree.unweighted = FALSE),
  list(alpha = 1.0, degree.cutoff = cor.spa['99%'], degree.type = 'sparsebn', degree.unweighted = FALSE),
  list(alpha = 0.0, degree.cutoff = cor.spa['99%'], degree.type = 'sparsebn', degree.unweighted = FALSE),
  #
  list(end = T)
  )

library(parallel)
library(foreach)
library(doParallel)

cl<-makeCluster(10)
registerDoParallel(cl)

foreach(ix = my.list, .combine = c) %dopar% {
 if (is.null(ix[['end']]) || !ix[['end']]) {
   run.me(ix)
 }
 NULL
}

stopCluster(cl)
```

# Parameters

```{r parms, echo=FALSE}
max.chars <- max(sapply(names(params), nchar))
for (ix.names in sort(names(params))) {
  prefix <- paste(array(' ', max.chars - nchar(ix.names)), collapse = '')
  if (is.vector(params[[ix.names]]) && length(params[[ix.names]]) == 1) {
    if (is.character(params[[ix.names]])) {
      flog.info('  %s%s: %s', prefix, ix.names, params[[ix.names]])
    }  else if (is.integer(params[[ix.names]])) {
      flog.info('  %s%s: % 11d', prefix, ix.names, params[[ix.names]])
    } else {
      flog.info('  %s%s: % 11.3f', prefix, ix.names, params[[ix.names]])
    }
  } else if (is.vector(params[[ix.names]])) {
    flog.info('  %s%s: %s', prefix, ix.names, paste(params[[ix.names]], collapse = ', '))
  } else {
    flog.info('  %s%s: (i do not know how to display this)', prefix, ix.names)
  }
}
```

# Load and normalize data

## Load TCGA data

```{r, eval=FALSE}
# xdata     - matrix with FPKM gene level expression
# ydata     - survival data
# xdata.raw - original matrix with possible multiple tissue samples from same indiviudal
prepare.tcga.survival.data(params$project, params$tissue, handle.duplicates = params$handle.duplicates)
```


```{r load.data, include=FALSE}
my.data <- run.cache(prepare.tcga.survival.data, params$project, params$tissue, handle.duplicates = params$handle.duplicates,
                                #
                                cache.prefix = 'tcga-data',
                                coding.genes = params$coding.genes,
                                show.message = T)
#
xdata     <- my.data$xdata
ydata     <- my.data$ydata
xdata.raw <- my.data$xdata.raw
#
#
xdata.digest.cache     <- my.data$xdata.digest
xdata.raw.digest.cache <- my.data$xdata.raw.digest
ydata.digest.cache     <- my.data$ydata.digest
#
rm(my.data)
```

## Load degree data

```{r, include=FALSE, eval=FALSE, fig.height=10, fig.width=10}
cutoff <- 0.6
load(sprintf('/home/averissimo/work/rpackages/brca.analysis/data/degree-%.6f.RData', cutoff))
degree.old      <- degree
degree.cor.inv  <- degree.cor.inv.weighted(xdata.raw, method = 'pearson', consider.unweighted = F, cutoff= cutoff)
degree.cor.inv2 <- degree.cor.inv.weighted2(xdata.raw,method = 'pearson', consider.unweighted = F, cutoff = cutoff)
degree.cor      <- degree.cor.weighted(xdata.raw, method = 'pearson', consider.unweighted = F, cutoff = cutoff)

df <- data.frame(degree.old, degree.cor, degree.cor.inv, degree.cor.inv2, 1 / degree.cor, 1 / degree.cor.inv, 1 / degree.cor.inv2)
df.m <- reshape2::melt(df, id.vars = 'degree.old')

ggplot(df.m) + geom_point(aes(degree.old, value, color = variable)) + 
  facet_wrap( ~ variable, scale = 'free', ncol = 2, dir = 'v') +
  theme(legend.position = 'none') + 
  scale_x_continuous(trans = 'log10') +
  scale_y_continuous(trans = 'log10')

qplot(degree.old, degree.cor) + ggtitle('Old vs cor')
qplot(degree.old, degree.cor.inv) + ggtitle('Old vs cor.inv') + 
  scale_x_continuous(trans = 'log10') +
  scale_y_continuous(trans = 'log10')
qplot(degree.old, degree.cor.inv2) + ggtitle('Old vs cor.inv2')
qplot(degree.old, 1 / degree.cor) + ggtitle('Old vs 1 / cor')
qplot(degree.old, 1 / degree.cor.inv) + ggtitle('Old vs 1 / cor.inv')
qplot(degree.old, 1 / degree.cor.inv2) + ggtitle('Old vs 1 / cor.inv2')
```

```{r degree.load}
#
# Load old matrix used in SPARSA conference
#
if (params$degree.type == 'oldie') {
  load(sprintf('/home/averissimo/work/rpackages/brca.analysis/data/degree-%.6f.RData', params$degree.cutoff))
  #
  # Load degree of network calculated summing the inverse of each weight
  #
} else if (params$degree.type == 'correlation.inv') {
  degree.cor.inv <- degree.cor.inv.weighted(xdata.raw,
    method              = params$degree.correlation,
    consider.unweighted = params$degree.unweighted,
    cutoff              = params$degree.cutoff,
    #
    show.message = T,
    n.cores = params$mc.cores)
  degree <- degree.cor.inv
  # save(degree, file = sprintf('../saves/degree.inv-%.5f.RData', params$degree.cutoff))
  write.csv(degree, file = sprintf('../saves/degree.inv-%.5f.csv', params$degree.cutoff))
  #
  # Load degree of network calculated using correlation
  # 
} else if (params$degree.type == 'correlation') {
  degree.cor <- degree.cor.weighted(xdata.raw, 
    method              = params$degree.correlation, 
    consider.unweighted = params$degree.unweighted, 
    cutoff              = params$degree.cutoff, 
    #
    show.message = T,
    n.cores = params$mc.cores)
  degree <- degree.cor
  save(degree, file = sprintf('../saves/degree-%.5f.RData', params$degree.cutoff))
  write.csv(degree, file = sprintf('../saves/degree-%.5f.csv', params$degree.cutoff))
  #
  # Load degree of network calculated using covariance
  #
} else if (params$degree.type == 'covariance') {
  degree.covariance <- degree.cov.weighted(xdata.raw, 
    method              = params$degree.correlation, 
    consider.unweighted = params$degree.unweighted, 
    cutoff              = params$degree.cutoff, 
    #
    n.cores = params$mc.cores, 
    show.message = T)
  
  save(degree.covariance, file = sprintf('../saves/degree-covariance-%.5f.RData', params$degree.cutoff))
  write.csv(degree.covariance, file = sprintf('../saves/degree-covariance-%.5f.csv', params$degree.cutoff))
  degree <- degree.covariance
  #
  # Load degree of network from sparsebn package (calulate bayesian network)
  #
} else if (params$degree.type == 'sparsebn') {
  degree.sparsebn <- degree.sparsebn.weighted(xdata.raw, cutoff = params$degree.cutoff, consider.unweighted = params$degree.unweighted)
  save(degree.sparsebn, file = sprintf('../saves/degree-sparsebn-%.5f.RData', params$degree.cutoff))
  write.csv(degree.sparsebn, file = sprintf('../saves/degree-sparsebn-%.5f.csv', params$degree.cutoff))
  degree <- degree.sparsebn
  #
  # Load degree of STRING network downloaded from external sources
  #
} else if (params$degree.type == 'string') {
  my.env <- new.env()
  load('../saves/degree-string.RData', envir = my.env)
  if (params$degree.unweighted) {
    degree.string <- my.env$degree_uw
  } else {
    degree.string <- my.env$degree_w
  }
  xdata.raw              <- xdata.raw[, colnames(xdata.raw) %in% names(degree.string)]
  xdata.raw.digest.cache <- digest.cache(xdata.raw)
  xdata                  <- xdata[, colnames(xdata) %in% names(degree.string)]
  xdata.digest.cache     <- digest.cache(xdata)
  degree                 <- degree.string[colnames(xdata)]
}
```

## Test / Training sets

```{r sets, echo=FALSE}
set.seed(params$seed)
ixs        <- balanced.train.and.test(which(ydata$status), which(!ydata$status), train.perc = params$train)
xdata.test <- xdata[ixs$test,]
ydata.test <- ydata[ixs$test,]
#
xdata.train <- xdata[ixs$train,]
ydata.train <- ydata[ixs$train,]

xdata.train.digest <- digest.cache(xdata.train)

flog.info('Size of sets: (size/events)\n * Train: %.2f%% :: %4d / %4d\n *  Test: %.2f%% :: %4d /%4d', 
          params$train * 100,
          nrow(xdata.train), 
          sum(ydata.train$status), 
          (1 - params$train) * 100,
          nrow(xdata.test),
          sum(ydata.test$status))
```

## Summary of data

### Data

```{r summary_data, echo=FALSE}
flog.info('Loaded data from %s TCGA', params$project)
flog.info('              type of tissue: %s', params$tissue)
flog.info('  observations (individuals): %d (%d event / %d censored)', nrow(xdata), sum(ydata$status), sum(!ydata$status))
flog.info('           variables (genes): %d', ncol(xdata))
```

### Survival

```{r surv_times, echo=FALSE}
ydata.month <- ydata
#ydata.month$time <- ydata$time / 365 * 12
ydata.month$status <- factor(ydata.month$status)
ydata.month <- ydata.month %>% mutate(status = fct_recode(status,
                                         'Alive (censored)' = 'FALSE',
                                         'Dead' = 'TRUE'))
#
ggplot(ydata.month) + geom_freqpoly(aes(time, color = status), bins = 150) +
  theme_minimal() + xlab('Time (month)') + ggtitle('Distribution of time per event') +
  theme(legend.position = 'top')
```

# Test physiological Variables

*note:* Plots with p-value `<= 0.05` are shown. Two types of p-values are used as criteria:

1. Univariate cox model
1. Log rank test when separating between high and low risk group

```{r test.clinical.variables, fig.height=15, echo=FALSE}
#
plot.all.clinical <- function() {
  df        <- data.frame()
  plot.list <- list()
  plot.p    <- c()
  for (ix.name in colnames(clinical$all)) {
    if (ix.name %in% c('days_to_death')) {
      next
    }
    u <- length(unique(clinical$all[[ix.name]]))
    if (is.numeric(clinical$all[[ix.name]]) || u == 2) {
      #
      #
      test.me        <- clinical$all[strtrim(rownames(ydata), 12), ix.name]
      if (all(sapply(test.me, is.character))) {
        test.me <- factor(test.me)
      }
      #
      names(test.me) <- rownames(ydata)
      test.me        <- test.me[!is.nan(test.me)]
      test.me        <- test.me[!is.na(test.me)]
      test.me.df     <- data.frame(time = ydata[names(test.me),1], status = ydata[names(test.me),2], test.me = test.me)
      colnames(test.me.df)[3] <- ix.name
      # build model with a single variable
      suppressWarnings(
        test.me.model <- coxph(Surv(time, status) ~ ., data = test.me.df, control = coxph.control(iter.max = 500))  
      )
      p.value       <- summary(test.me.model)$coefficients[1,'Pr(>|z|)']
      #
      # skip if model is not right
      if (is.na(p.value)) { next }
      desc.values <- c(0,0)
      if (is.factor(test.me)) {
        desc.values <- paste(levels(test.me), collapse = ', ')
        my.names        <- names(test.me)
        levels(test.me) <- c(0,1)
        test.me         <- as.numeric(as.character(test.me))
        names(test.me)  <- my.names
      } else {
        desc.values <- sprintf('min: %g -- max %g -- median %g', min(test.me), max(test.me), median(test.me))
      }
      #
      df <- rbind(df, data.frame(name    = ix.name, 
                                 numeric = is.numeric(clinical$all[[ix.name]]), 
                                 unique  = u, 
                                 p.value = p.value,
                                 desc    = desc.values))
      #
      my.coef        <- coef(test.me.model)
      names(my.coef) <- 'test.me'
      ydata.me       <- data.frame(time = ydata[names(test.me),1], status = ydata[names(test.me),2] * 1)
      test.me.km     <- draw.kaplan(as.vector(my.coef), as.vector(test.me), ydata.me, filename = ix.name, legend.outside = F)
      # build list to multiplot
      #  but skip if not significant
      if (p.value > 0.05 && test.me.km$pvalue > 0.05) { next }
      plot.list[[length(plot.list) + 1]] <- test.me.km$plot
      plot.p <- c(plot.p, test.me.km$pvalue)
    }
  }
  ncol       <- 3
  p.value.ix <- sort(plot.p, index.return = T)$ix # used to sort layout by p.values
  layout     <- matrix(c((1:length(plot.list))[p.value.ix], rep(NA, (ncol * ceiling(length(plot.list) / ncol)) - (length(plot.list)))),
                   byrow = T, ncol = ncol) 
  return(list(plot.list = plot.list, layout = layout, df = df))
}

all.plots <- run.cache(plot.all.clinical, show.message = F)

multiplot(plotlist = all.plots$plot.list, layout = all.plots$layout)
knitr::kable(dplyr::arrange(dplyr::select(all.plots$df, name, p.value, desc), p.value))
```

# Pre-processing

* Selects a random subset of genes (all if `r params$subset == Inf`)
* Prepares the degree vector to be used in `glmnet`

```{r sample.xdata, echo = FALSE}
# Sample xdata if it is necessary
xdata.ix <- seq(ncol(xdata))
xdata.ix.no.added <- xdata.ix

if (params$subset < ncol(xdata.train)) {
  set.seed(params$seed)
  xdata.ix <- sample(xdata.ix, params$subset)
} 
set.seed(params$seed)
xdata.train.digest <- digest.cache(xdata.train[, xdata.ix])
```

## Preparing degree vector

* Normalize degree between 0 and 1
* DegreeCox: 1 - degree
* OrphanCox: degree
* `trans.fun` is a double power to scale the values

```{r transformation_function}
trans.fun <- function(x, 
                      a = .20 - 1,
                      b = -1, 
                      g = -1) { 
  return(a + 10^(-b * (exp(x) + g)))
}

trans.fun2 <- function(x, 
                      a = .20 - 1,
                      b = -1, 
                      g = -1) { 
  return(a + exp(-b * (exp(x) + g)))
}

trans.fun3 <- function(x, 
                      a = .20 - 1,
                      b = -1, 
                      g = -1) { 
  return(a + 10^(-b * (10^x + g)))
}
x <- seq(0,1,.005)
trans.plot <- melt(data.frame(x, fun1 = trans.fun(x), fun2 = trans.fun2(x), fun3 = trans.fun3(x)), id.vars = 'x') %>%
  filter(variable == 'fun1') %>%
  ggplot() + 
  geom_line(aes(x, value, color = variable)) + 
  #facet_wrap( ~ variable, scales = 'free_y') +
  theme(legend.position = 'none') +
  xlab('Scaled Degree') + 
  ggtitle('')
trans.plot
```

```{r prepare.penalty, echo=FALSE}
original.penalty.factor        <- degree[xdata.ix.no.added]
names(original.penalty.factor) <- colnames(xdata.train[,xdata.ix.no.added])

# if (params$add.age.at.diag) {
#   #
#   age.at.diag.norm <- c(xdata.train[,'age.at.diag'],
#                         xdata.test[,'age.at.diag'])
#   age.at.diag.norm <- age.at.diag.norm[colnames(xdata)]
#   age.cov <- unlist(mclapply(xdata.ix.no.added, function(ix) {
#     co.exp <- cov(age.at.diag.norm, xdata[ix,], method = 'pearson')
#     if (abs(co.exp) >= params$degree.perct)
#       return(co.exp)
#     else {
#       return(0)
#     }
#   }, mc.cores = params$mc.cores))
#   original.penalty.factor <- original.penalty.factor + age.cov
#   original.penalty.factor <- c(original.penalty.factor, age.at.diag = sum(age.cov))
# }

##########################
#                        #
#   SUPER IMPORTANT!!!!  #
#                        #
##########################
original.penalty.factor[is.na(original.penalty.factor)] <- 0
norm.orig.penalty.factor <- original.penalty.factor / max(original.penalty.factor[!is.na(original.penalty.factor)])

#
#
# DegreeCox (old and log(old))
#
penalty.factor.degree.log <- penalty.factor.degree.old <- 1 / norm.orig.penalty.factor

inf.ix <- is.infinite(penalty.factor.degree.old) # index for infinite values

# log(old)
log.penal                          <- log(penalty.factor.degree.old[!inf.ix]) + 1
penalty.factor.degree.log[!inf.ix] <- log.penal
penalty.factor.degree.log[inf.ix]  <- max(log.penal) + 1

# old
non.log                           <- penalty.factor.degree.old[!inf.ix]
penalty.factor.degree.old[inf.ix] <- max(non.log) + 1

#
# DegreeCox heuristic
#
penalty.factor.degree.new <-trans.fun(1 - norm.orig.penalty.factor)

#
# OrphanCox
#
penalty.factor.orphan <- trans.fun(norm.orig.penalty.factor)

my.df <- data.frame(ix                        = seq_along(penalty.factor.degree.old), 
                    penalty.factor.degree.old = penalty.factor.degree.old, 
                    penalty.factor.degree.new = penalty.factor.degree.new,
                    penalty.factor.degree.log = penalty.factor.degree.log,
                    penalty.factor.orphan     = penalty.factor.orphan,
                    original                  = original.penalty.factor)
```

### Original degree frequency

```{r plots_x_no_scale, echo=FALSE, fig.height=10, warning=FALSE}
transf.d <- melt.data.frame(my.df[,c('ix', 
                                     'original', 
                                     'penalty.factor.degree.old',
                                     'penalty.factor.degree.log',
                                     'penalty.factor.degree.new',
                                     'penalty.factor.orphan')], id.vars = c('ix'), variable_name = 'Type')

levels(transf.d$Type) <- levels(transf.d$Type) %>%
  gsub('original', 'Original', .) %>%
  gsub('penalty.factor.degree.old', 'Degree (old)', .) %>%
  gsub('penalty.factor.degree.log', 'Degree (log(old))', .) %>%
  gsub('penalty.factor.degree.new', 'Degree (heuristic)', .) %>%
  gsub('penalty.factor.orphan', 'Orphan', .)


#degree.factor.freq.plot <- 
ggplot(transf.d) +
  geom_freqpoly(aes(value, color = Type), alpha = 0.8, bins = 200, size = 1.5) +
  theme_minimal() + theme(legend.position = 'top') +
  facet_wrap( ~ Type, ncol = 1, scale = 'free_x') +
  scale_y_continuous(trans = 'log10') +
  xlab('Penalty') +
  ylab('Frequency count (log10 scale)')
```

```{r plots_x_scale, echo=FALSE, fig.height=10, warning=FALSE}
transf.d <- melt.data.frame(my.df[,c('ix', 
                                     'original', 
                                     'penalty.factor.degree.old',
                                     'penalty.factor.degree.log',
                                     'penalty.factor.degree.new',
                                     'penalty.factor.orphan')], id.vars = c('ix'), variable_name = 'Type')

levels(transf.d$Type) <- levels(transf.d$Type) %>%
  gsub('original', 'Original', .) %>%
  gsub('penalty.factor.degree.old', 'Degree (old)', .) %>%
  gsub('penalty.factor.degree.log', 'Degree (log(old))', .) %>%
  gsub('penalty.factor.degree.new', 'Degree (heuristic)', .) %>%
  gsub('penalty.factor.orphan', 'Orphan', .)


#degree.factor.freq.plot <- 
ggplot(transf.d) +
  geom_freqpoly(aes(value, color = Type), alpha = 0.8, bins = 200, size = 1.5) +
  theme_minimal() + theme(legend.position = 'top') +
  facet_wrap( ~ Type, ncol = 1, scale = 'free_x') +
  scale_y_continuous(trans = 'log10') +
  scale_x_continuous(trans = 'log10') +
  xlab('Penalty (log10 scale)') +
  ylab('Frequency count (log10 scale)')
```


# Model Inference

```{r model_declaration, include=FALSE}
my.glmnet <- function(prefix, penalty.factor, target, lambda.min.ratio = .001, show.messages = FALSE) {
  new.model <- run.cache(glmnet,
                                   xdata.train[,xdata.ix], Surv(ydata.train[,1], ydata.train[,2]), 
                                   family           ='cox', 
                                   alpha            = params$alpha, 
                                   nlambda          = 1000,
                                   lambda.min.ratio = lambda.min.ratio,
                                   standardize      = F,
                                   penalty.factor   = penalty.factor,
                                   #
                                   force.recalc = F,
                                   cache.prefix = gsub('_', '.', gsub('_old', '', prefix)),
                                   cache.digest = list(xdata.train.digest),
                                   show.message = show.messages)

if (any(new.model$df == target)) {
  var.ix <- which(new.model$df == target)
} else if (any(new.model$df > params$target.vars)) {
  new.target <- min(new.model$df[new.model$df > target])
  var.ix <- which(new.model$df == new.target)
} else {
  new.target <- max(new.model$df[new.model$df < target])
  var.ix <- which(new.model$df == new.target)
}
  new.target.lambda <- new.model$lambda[var.ix[sort(var.ix, decreasing = T, index.return = T)$ix[1]]]
  new.coef <- as.vector(coef(new.model, s = new.target.lambda))
  names(new.coef) <- colnames(xdata.train[,xdata.ix])
  return(list(model = new.model, lambda = new.target.lambda, coef = new.coef))
}
```

```{r cvmodel_declaration, include=FALSE}
my.cv.glmnet <- function(prefix, penalty.factor, nfolds = 10, lambda.min.ratio = .001, show.messages = FALSE) {
  #
  set.seed(params$seed)
  #
  fold.tmp <- balanced.cv.folds(which(ydata$status), which(!ydata$status), nfolds = nfolds)
  foldid <- array(0, nrow(xdata))
  foldid[which(ydata$status)] <- fold.tmp$output[[1]]
  foldid[which(!ydata$status)] <- fold.tmp$output[[2]]
  #
  new.model <- run.cache(cv.glmnet,
                                    xdata, Surv(ydata[,1], ydata[,2]), 
                                    family           ='cox', 
                                    foldid           = foldid,
                                    alpha            = params$alpha, 
                                    nlambda          = 1000,
                                    lambda.min.ratio = lambda.min.ratio,
                                    standardize      = F,
                                    penalty.factor   = penalty.factor,
                                    #
                                    mc.cores         = params$mc.cores,
                                    force.recalc = F,
                                    cache.prefix = prefix,
                                    cache.digest = list(xdata.train.digest),
                                    show.message = show.messages)
  new.coef <- as.vector(coef(new.model, s = 'lambda.min'))
  new.target.lambda <- new.model$lambda.min
  #
  return(list(model = new.model, lambda = new.target.lambda, coef = new.coef))
}
```

## Cross-validation

Testing classic elastic-net, DegreeCox and OrphanCox with cross-validation to find optimal number of variables for comparisson models.

```{r cv.models, echo=FALSE, eval=FALSE}
show.cv.info <- function(my.model, name) {
  selected.genes <- sort(colnames(xdata)[my.model$coef != 0])
  flog.info(' * %s: %d -- %s', name, sum(my.model$coef != 0), paste(selected.genes, collapse = ', '))
  return(selected.genes)
}

cv.classic <- my.cv.glmnet('cv.classic', rep(1, ncol(xdata)), show.messages = FALSE,  lambda.min.ratio = .001)
cv.degree  <- my.cv.glmnet('cv.degree', penalty.factor.degree.new, show.messages = FALSE, lambda.min.ratio = .001)
cv.orphan  <- my.cv.glmnet('cv.degree', penalty.factor.orphan, show.messages = FALSE, lambda.min.ratio = .001)

flog.info('10-fold cross-validation')
cv.classic.genes <- show.cv.info(cv.classic, 'classic')
cv.degree.genes  <- show.cv.info(cv.degree, ' degree')
cv.orphan.genes  <- show.cv.info(cv.orphan, ' orphan')

tryCatch({
vv <- Venn(list(Classic = cv.classic.genes, Degree = cv.degree.genes, Orphan = cv.orphan.genes))
plot(vv, doWeights = FALSE)
}, error = function(err) { flog.error('Probel with %s', err)})
#
km.cv <- list()

km.cv[['cv.classic']] <- draw.kaplan(list(CV.Classic = cv.classic$coef), xdata[,xdata.ix], ydata, filename = 'CV.Classic', legend.outside = F)
km.cv[['cv.degree']] <- draw.kaplan(list(CV.Degree = cv.degree$coef), xdata[,xdata.ix], ydata, filename = 'CV.Degree', legend.outside = F)
km.cv[['cv.orphan']] <- draw.kaplan(list(CV.Orphan = cv.orphan$coef), xdata[,xdata.ix], ydata, filename = 'CV.Orphan', legend.outside = F)

for (ix in names(km.cv)) {
  print(km.cv[[ix]]$plot)
}
```

```{r list_init, include=FALSE}
#
models  <- list()
lambdas <- list()
coefs   <- list()
result  <- list()
table.data <- list()
```

```{r calc.models, echo=FALSE}
glmnet.params <- list()

for (target.name in names(params$target.vars)) {
  target <- params$target.vars[[target.name]]
  glmnet.params <- c(glmnet.params, list(list(penalty = rep(1, ncol(xdata.train)), name = 'glmnet', target = target, target.name = target.name)))
  glmnet.params <- c(glmnet.params, list(list(penalty = penalty.factor.degree.new, name = 'degree_new', target = target, target.name = target.name)))
  glmnet.params <- c(glmnet.params, list(list(penalty = penalty.factor.orphan, name = 'orphan', target = target, target.name = target.name)))
  if (params$calc.params.old) {
   glmnet.params <- c(glmnet.params, list(list(penalty = penalty.factor.degree.old, name = 'degree_old', target = target, target.name = target.name)))
  glmnet.params <- c(glmnet.params, list(list(penalty = penalty.factor.degree.log, name = 'degree_log', target = target, target.name = target.name))) 
  }
}

outer.result <- mclapply(seq_along(glmnet.params), function(ix) {
#outer.result <- lapply(seq_along(glmnet.params), function(ix) {
  el       <- glmnet.params[[ix]]
  ix.name  <- sprintf('%s.%s.%d', el$name, el$target.name, el$target)
  ix.cache <- sprintf('%s_models', el$name)
  #
  suppressWarnings(
  result  <- my.glmnet(ix.cache, el$penalty, el$target, show.messages = F)
  )
  
  if (sum(result$coef != 0) < (target - 5)) {
    suppressWarnings(
      result <- my.glmnet(ix.cache, el$penalty, el$target, lambda.min.ratio = .00001, show.messages = F)
    )
  }
  #
  return(list(result = result, name = ix.name))
#})
}, mc.cores = min(params$mc.cores, length(glmnet.params)), mc.allow.recursive = FALSE)


for (ix in outer.result) {
  result[[ix$name]]  <- ix$result
  models[[ix$name]]  <- ix$result$model
  lambdas[[ix$name]] <- ix$result$lambda
  coefs[[ix$name]]   <- ix$result$coef
}
```

```{r models_variables, echo=FALSE}
flog.info('Number of variables per model:')
for (ix in names(coefs)) {
  flog.info('  * %s:\t %d variables', ix, sum(coefs[[ix]] != 0))
}
```

# Results

## Relative risk distribution

```{r fitted.test.train.orphan, include=FALSE}
build.fit.df <- function(obj) {
  fitted.network <- data.frame()
  
  for (ix.name in names(obj)) {
    risk.a <- predict(obj[[ix.name]]$model, newx = xdata.train[,xdata.ix], s = obj[[ix.name]]$target, type = 'response')
    risk.b <- predict(obj[[ix.name]]$model, newx = xdata.test[,xdata.ix], s = obj[[ix.name]]$target, type = 'response')
    
    a <- data.frame(relative.risk = as.vector(risk.a), set = 'Train', type = ix.name, stringsAsFactors = FALSE)
    b <- data.frame(relative.risk = as.vector(risk.b), set = 'Test', type = ix.name, stringsAsFactors = FALSE)
    
    a$mean <- mean(a$relative.risk)
    b$mean <- mean(b$relative.risk)
    
    fitted.network <- rbind(fitted.network, a, b)
  }
  return(fitted.network)
}

this.list <- list()
for (ix.name in names(models)) {
  this.list[[ix.name]] <- list(model = models[[ix.name]], target = lambdas[[ix.name]])
}

fitted.network <- run.cache(build.fit.df, this.list, show.message = F)
```

```{r risk, fig.height=18}
ggplot(fitted.network) +
  geom_freqpoly(aes(relative.risk, color = set), bins = 150) + theme_minimal() +
  geom_vline(aes(xintercept = mean), linetype = 'dotted', color = '#999999') +
  geom_text(aes(x = mean, y = -.5, label = sprintf(' Mean of relative risk %g', mean), hjust = 0), color = '#999999', inherit.aes = FALSE, check_overlap = TRUE) + 
  facet_wrap( ~ type + set, ncol = 2) + 
  ggtitle('Distribution of risk in Classic model') +
  theme(legend.position = 'none')
```

## Kaplan-Meier Curves

```{r km.name, include=FALSE}
km.name <- function(title, alpha, is.network = NULL) {
  l1 <- sprintf('%.1f * L1', alpha)
  l2 <- sprintf('%.1f * L2', 1 - alpha)
  sep <- ' + '
  subtitle <- 'Classic elastic net'
  if (alpha == 1) {
    l1 <- 'L1'
    l2 <- ''
    sep <- ''
  } else if (alpha == 0) {
    l1 <- ''
    l2 <- 'L2'
    sep <- ''
  }
  type <- if (is.null(is.network)) {
    subtitle <- 'Classic Elastic Net model'
    ''
  } else {
    #is.network <- sub('\\..*', '', is.network)
    is.network <- gsub('\\.((classic\\.cv)|(degree\\.cv)|(orphan\\.cv))\\.[0-9]+$', '', is.network)
    type <- if (is.network == 'glmnet') {
      subtitle <- 'Classic Elastic Net model'
      ''
    } else if (is.network == 'degree_log') {
      subtitle <- 'DegreeCox: Hubs are promoted -- log'
      'Promotes high degree with '
    } else if (is.network == 'degree_new') {
      subtitle <- 'DegreeCox: Hubs are promoted -- heuristic'
      'Promotes high degree with '
    } else if (is.network == 'degree_old') {
      subtitle <- 'DegreeCox: Hubs are promoted -- old'
      'Promotes high degree with '
    } else if (is.network == 'orphan') {
      subtitle <- 'OrphanCox: Low connected nodes are promoted'
      'Promotes low degree with '
    } 
  }
  return(ggtitle(sprintf('%s: %s%s%s%s', title, type, l1, sep, l2), subtitle = subtitle))
}
```

```{r calc.km, include=FALSE}
my.draw.kaplan <- function(coef.l, filename, test.set = F) { 
  if (test.set) {
    return(draw.kaplan(coef.l, xdata.test[,xdata.ix], ydata.test, filename = filename, legend.outside = F, ylim = c(0,1))) 
  } else {
    draw.kaplan(coef.l, xdata.train[,xdata.ix], ydata.train, filename = filename, legend.outside = F, ylim = c(0,1))
  }
}

#
km.train <- list()
km.test  <- list()
#
for (ix.name in names(coefs)) {
  km.train[[ix.name]] <- my.draw.kaplan(list(ix.name = coefs[[ix.name]]), filename = 'Train set')
  km.test[[ix.name]]  <- my.draw.kaplan(list(ix.name = coefs[[ix.name]]), filename = 'Test set', test.set = T)
}
```

```{r plot.km, fig.height= 40, echo=FALSE, fig.width=10}
my.km <- list()
ix <- 1
for (ix.name in names(coefs)) {
  my.km[[ix]] <- km.train[[ix.name]]$plot + km.name('Train', params$alpha, ix.name)
  my.km[[ix + 1]]  <- km.test[[ix.name]]$plot  + km.name('Test',  params$alpha, ix.name)
  ix <- ix + 2
}

multiplot(plotlist = my.km, ncol = 2, layout = matrix(seq_along(my.km), ncol = 2, byrow = T))
```

## C-Index

```{r c_index_declaration, include=FALSE}
c.index.fun <- function(all.pairs, fitted.risk, ydata) {
  unlist(mclapply(seq(ncol(all.pairs)), function(ix) {
    ix.1 <- all.pairs[1,ix]
    ix.2 <- all.pairs[2,ix]
    return(my.c.index.cmp(fitted.risk[ix.1], fitted.risk[ix.2], 
                   ydata[ix.1,1], ydata[ix.2,1],
                   ydata[ix.1,2], ydata[ix.2,2]))
  }, mc.cores = params$mc.cores))
}
```

```{r c.index,echo=FALSE}
all.pairs <- combn(nrow(xdata.train), 2)
c.index.train <- list()
c.index.test  <- list()

flog.info('C-index for train set:')

#
#
# Train
#

fit.risk <- function(coef.v, xdata, ydata, model.name, show.message = FALSE) {
  # fitted.risk  <- as.vector(predict(models$glmnet, newx = xdata.train[,xdata.ix], s = lambdas$glmnet, type = 'response')) 
  fitted.risk <- exp(as.vector(xdata[,xdata.ix] %*% coef.v))
  c.res <- run.cache(c.index.fun, all.pairs, fitted.risk, ydata, show.message = F)
  c.res <- sum(c.res) / sum(c.res != 0)
  if (show.message) flog.info(' * %s: %f', model.name, c.res)
  return(c.res)
}

for (ix.name in names(coefs)) {
c.index.train[[ix.name]] <- fit.risk(coefs[[ix.name]], xdata.train, ydata.train, ix.name,  show.message = TRUE)
}

flog.info('')
#
#
# Test
#

all.pairs <- combn(nrow(xdata.test), 2)

flog.info('C-index for test set:')

for (ix.name in names(coefs)) {
c.index.test[[ix.name]] <- fit.risk(coefs[[ix.name]], xdata.train, ydata.train, ix.name,  show.message = TRUE)
}

```

Summary

```{r summary, echo=FALSE}
table.data <- data.frame()
for (ix.name in names(coefs)) {
  table.data <- rbind(table.data, data.frame(
                           weighted      = !params$degree.unweighted,
                           penalization  = params$degree.type,
                           project       = params$project,
                           tissue        = params$tissue,
                           cutoff        = params$degree.cutoff,
                           coding.genes  = params$coding.genes,
                           alpha         = params$alpha,
                           model         = ix.name,
                           nvars         = sum(coefs[[ix.name]] != 0),
                           km.train      = km.train[[ix.name]]$pvalue,
                           km.test       = km.test[[ix.name]]$pvalue,
                           c.index.train = c.index.train[[ix.name]],
                           c.index.test  = c.index.test[[ix.name]]))
}
table.data
```


## Non-zero genes

```{r, include=FALSE}
coefs.v <- list()
non.zero.df.result <- NULL
for (ix.name in names(coefs)){
  flog.info('Working on %s', ix.name)
  coefs.v[[ix.name]] <- coefs[[ix.name]]
  non.zero.ix        <- which(coefs.v[[ix.name]] != 0)
  #
  names.tmp <- names(coefs.v[[ix.name]])[non.zero.ix]
  coef.tmp  <- coefs.v[[ix.name]][non.zero.ix]
  if (length(coefs.v) == 1) {
    flog.info('  * Len == 0')
    non.zero.df.result <- data.frame(gene.id = names.tmp, coef = coef.tmp)
    first.name <- ix.name
  } else {
    flog.info('  * Len > 0')
    non.zero.df2 <- data.frame(gene.id = names.tmp, coef = coef.tmp)
    suffix <- c('', sprintf('.%s', ix.name))
    non.zero.df.result  <- dplyr::full_join(non.zero.df.result, non.zero.df2, by = c('gene.id'), suffix = suffix)
  }
}
colnames(non.zero.df.result)[2] <- sprintf('coef.%s', first.name)
#
non.zero.df.out <- cbind(non.zero.df.result, degree = as.vector(original.penalty.factor[non.zero.df.result$gene.id]))
```


```{r non.zero, include=FALSE}
this.name <- function(this.coef) {
  tryCatch({
    marts <- biomaRt::listMarts()
    index <- grep("ensembl genes",marts$version, ignore.case = TRUE)
    mart <- biomaRt::useMart(marts$biomart[index])
    mart <- run.cache(biomaRt::useMart,marts$biomart[index], 'hsapiens_gene_ensembl', 
                                 cache.prefix = 'biomart')
    results <- biomaRt::getBM(attributes = c("external_gene_name", "ensembl_gene_id"),
                     filters = "ensembl_gene_id", values = this.coef,
                     mart = mart)
    return(arrange(results, external_gene_name))
  }, error = function(msg) {
    flog.warn('Error when finding gene names:\n\t%s', msg)
  })
  return(data.frame(ensembl_gene_id = this.coef, external_gene_name = this.coef, stringsAsFactors = FALSE))
  
}
gene.names <- this.name(non.zero.df.out$gene.id)
new.t <- non.zero.df.out
ixs <- gene.names[unlist(sapply(new.t$gene.id, function(s) { which(gene.names$ensembl_gene_id == s) })),]
new.t$gene.id[new.t$gene.id %in% ixs$ensembl_gene_id] <- ixs$external_gene_name

gene.ids <- non.zero.df.out$gene.id
non.zero.df.out$gene.id <- gsub('ENSG0*', 'ENSG', non.zero.df.out$gene.id)
non.zero.df.out$gene.name <- new.t$gene.id
col.ix <- colnames(non.zero.df.out) %in% c('gene.id', 'gene.name', 'degree')
non.zero.df.out <- non.zero.df.out[,c(which(col.ix), which(!col.ix))]
```

### Venn Diagram of selected genes

#### Overlap between models *(with same target number of variables)*

```{r venn.coef, echo=FALSE}
all.names  <- names(coefs)
all.names <- all.names[grep('^(degree_new)|^(orphan\\.)|^(glmnet\\.)', all.names)]
all.model  <- unique(gsub('^([a-zAZ]+)\\.(.+)$', '\\1', gsub('_new', '', all.names)))
all.origin <- gsub('^([a-zAZ]+)\\.(.+)$', '\\2', gsub('_new', '', all.names))

for (type in unique(all.origin)) {
  ll <- list()
  for (ix.name in all.names[which(grepl(type, all.names))]) {
     label <- gsub(sprintf('\\.%s', type), '', ix.name)
     label <- gsub('glmnet', 'classic', label)
     label <- proper(label)
     ll[[label]] <- sort(non.zero.df.out$gene.id[!is.na(non.zero.df.out[, sprintf('coef.%s', ix.name)])])
  }
  tryCatch({
    vv <- Venn(ll)
    gridExtra::grid.arrange(grid::grid.grabExpr(plot(vv, doWeights = FALSE)), top= sprintf('Target variables: %s', proper(type)))
  }, error = function(err) { flog.error('Probel with %s', err)})
}
```

#### Same model type *(either degree, classic or orphan)* with different lambdas

```{r}
for (type in unique(all.model)) {
  type <- gsub('degree', 'degree_new', type)
  ll <- list()
  for (ix.name in all.names[which(grepl(sprintf('^%s', type), all.names))]) {
     label <- gsub(sprintf('^%s\\.', type), '', ix.name)
     label <- gsub('glmnet', 'classic', label)
     label <- gsub('cv\\.', '', label)
     label <- proper(label)
     ll[[label]] <- sort(non.zero.df.out$gene.id[!is.na(non.zero.df.out[, sprintf('coef.%s', ix.name)])])
  }
  tryCatch({
    vv <- Venn(ll)
    gridExtra::grid.arrange(grid::grid.grabExpr(plot(vv, doWeights = FALSE)), top= sprintf('Model: %s', proper(type)))
  }, error = function(err) { flog.error('Probel with %s', err)})
}
```


### Table of genes in models

```{r genes.table, echo=FALSE}
knitr::kable(head(non.zero.df.out, n = 30))
```

## Hallmarks of Cancer links

```{r hallmarks, fig.width=10, warning=FALSE}
base.url <- sprintf('http://chat.lionproject.net/chartdata?measure=%s&hallmarks=%s', 'count', 'full')
# base.url <- 'http://chat.lionproject.net/?measure=npmi&chart_type=doughnut&hallmarks=full'

all.genes <- sort(unique(non.zero.df.out$gene.name))

call.url <- sprintf('%s&q=%s', base.url, paste(all.genes, collapse = '&q='))

lines <- run.cache(read_lines, url(call.url), cache.digest = list(digest.cache(call.url)))
item_group <- cumsum(grepl("^[A-Za-z0-9\\._,-]+\tcount", lines))
all.items <- list()
col.names <- c()
clean.rows <- lapply(split(lines, item_group), function(ix) { 
    item.id <- gsub("\tcount","", ix[1])
    # prepare results
    item.val <- list()
    my.names <- c('gene.name')
    my.values <- c(item.id)
    for (line in ix[-1]) {
      if (line == '') {
        next
      }
      my.split <- strsplit(line, '\t')[[1]]
      # flog.info('  %s -- %s',my.split[1], my.split[2] )
      my.names  <- c(my.names, my.split[1])
      my.values <- c(my.values, my.split[2])
      col.names <<- c(col.names, my.split[[1]])
    }
    names(my.values) <- my.names
    all.items[[item.id]] <- my.values
})

col.names <- unique(col.names)
df <- data.frame()
for (ix in clean.rows) {
  # convert to numeric
  new.ix <- as.numeric(ix[names(ix) != 'gene.name'])
  # set previous names
  names(new.ix) <- names(ix)[names(ix) != 'gene.name']
  # create temporary data frame with controlled column names
  temp.df <- data.frame(t(new.ix[col.names]))
  rownames(temp.df) <- ix['gene.name']
  df <- rbind(df, temp.df)
}

df.scaled <- t(scale(t(df)))
na.ix <- which(apply(df.scaled, 1, function(col) {
  return(all(is.nan(col)))
}))
df.scaled <- df # use counts

df.no.hallmarks <- data.frame(gene.name = sort(rownames(df.scaled)[na.ix]), stringsAsFactors = FALSE)

for (ix.name in names(coefs)) {
  df.no.hallmarks[, ix.name] <- 1 - (df.no.hallmarks$gene.name %in% non.zero.df.out[!is.na(non.zero.df.out[[paste0('coef.',ix.name)]]), 'gene.name']) * 1
}
ggplot(melt(df.no.hallmarks, id.vars = 'gene.name'), aes(gene.name,variable, fill=value)) + geom_raster() + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

```

```{r biclust, fig.height=10}
df.scaled <- data.frame(gene.name = rownames(df.scaled), df.scaled, stringsAsFactors = FALSE)
df.scaled <- df.scaled[-na.ix,]

for (ix.name in names(coefs)) {
  df.scaled[, ix.name] <- (df.scaled$gene.name %in% non.zero.df.out[!is.na(non.zero.df.out[[paste0('coef.',ix.name)]]), 'gene.name']) * 1
}

for (ix.name in names(coefs)) {
  if (sum(df.scaled[[ix.name]] == 1) == 0) {
    flog.warn('No hallmark genes for: %s', ix.name)
    next
  }
  df.scaled.filter <- df.scaled[df.scaled[[ix.name]] == 1, !colnames(df.scaled) %in% names(coefs)]
  df.melt <- melt(df.scaled.filter, 
                  id.vars = c('gene.name'))
  print(
    ggplot(df.melt, aes(gene.name,variable, fill=value)) + 
      geom_raster() +
      theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
      ggtitle(ix.name)
  )
  my.mat <- df.scaled.filter[,-1]
  tryCatch({
  biclust(as.matrix(my.mat), method=BCBimax(), minr=2, minc=2, number=100) %>%
    drawHeatmap(x = as.matrix(my.mat), bicResult = ., number = 1) # shown in picture below
  }, error = function(err) { flog.error('Error: %s', err)})
}
```

```{r, eval=FALSE, include=FALSE}
df.scaled.filter <- df.scaled[df.scaled[[ix.name]] == 1,!colnames(df.scaled) %in% names(coefs)]
if (nrow(df.scaled.filter) > 1) {
  hclust.res <- hclust(dist(as.matrix(df.scaled.filter[,-1])))
  plot(hclust.res)

df.melt <- melt(df.scaled.filter[hclust.res$order,], 
                id.vars = c('gene.name'))

df.melt$variable <- factor( df.melt$variable, levels = colnames(df.scaled.filter), labels = seq_along( colnames(df.scaled.filter) ) )
df.melt$gene.name <- factor( df.melt$gene.name, levels = rownames(df.scaled.filter)[hclust.res$order],  labels = hclust.res$labels[hclust.res$order] )

print(
  ggplot(df.melt, aes(gene.name,variable, fill=value)) + 
    geom_raster() +
    theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
    ggtitle(ix.name)
) 
} else {
  flog.error('Rows must be more then 1')
}
```


# `r params$ntimes` Runs

```{r call.results.decl, echo=FALSE, eval=FALSE}
# train.perc <- params$train
# subset <- params$subset
# seed <- 1985
call.results <- function(seed, xdata, ydata, train.perc, subset, penalty.factor.degree.new, penalty.factor.degree.old, penalty.factor.orphan) {
  set.seed(seed)
  
  #
  # Build training data
  ixs <- balanced.train.and.test(which(ydata$status), which(!ydata$status), train.perc = train.perc)
  xdata.test <- xdata[ixs$test,]
  ydata.test <- ydata[ixs$test,]
  #
  xdata.train <- xdata[ixs$train,]
  ydata.train <- ydata[ixs$train,]
  
  xdata.ix <- seq(ncol(xdata))
  xdata.ix.no.added <- xdata.ix
  
  if (subset < ncol(xdata.train)) {
    xdata.ix <- sample(xdata.ix, params$subset)
  } 
  
  xdata.train.digest <- digest.cache(xdata.train[, xdata.ix])
  
  #
  # MODELS
  #
  
  models  <- list()
  lambdas <- list()
  coefs   <- list()
  result  <- list()
  
  glmnet.params <- list()

  for (target.name in names(params$target.vars)) {
    target <- params$target.vars[[target.name]]
    glmnet.params <- c(glmnet.params, list(list(penalty = rep(1, ncol(xdata.train)), 
                                                name = 'glmnet', 
                                                target = target, 
                                                target.name = target.name)))
    glmnet.params <- c(glmnet.params, list(list(penalty = penalty.factor.degree.new, 
                                                name = 'degree_new', 
                                                target = target, 
                                                target.name = target.name)))
    glmnet.params <- c(glmnet.params, list(list(penalty = penalty.factor.orphan, 
                                                name = 'orphan', 
                                                target = target, 
                                                target.name = target.name)))
    if (params$calc.params.old) {
     glmnet.params <- c(glmnet.params, list(list(penalty = penalty.factor.degree.old, 
                                                 name = 'degree_old', 
                                                 target = target, 
                                                 target.name = target.name)))
    glmnet.params <- c(glmnet.params, list(list(penalty = penalty.factor.degree.log, 
                                                name = 'degree_log',
                                                target = target, 
                                                target.name = target.name))) 
    }
  }
  
  outer.result <- mclapply(seq_along(glmnet.params), function(ix) {
  #outer.result <- lapply(seq_along(glmnet.params), function(ix) {
    el       <- glmnet.params[[ix]]
    ix.name  <- sprintf('%s.%s.%d', el$name, el$target.name, el$target)
    ix.cache <- sprintf('%s_models', el$name)
    #
    suppressWarnings(
    result  <- my.glmnet(ix.cache, el$penalty, el$target, show.messages = F)
    )
    
    if (sum(result$coef != 0) < (target - 5)) {
      suppressWarnings(
        result <- my.glmnet(ix.cache, el$penalty, el$target, lambda.min.ratio = .00001, show.messages = F)
      )
    }
    #
    return(list(result = result, name = ix.name))
  #})
  }, mc.cores = min(params$mc.cores, length(glmnet.params)), mc.allow.recursive = FALSE)
  
  
  for (ix in outer.result) {
    result[[ix$name]]  <- ix$result
    models[[ix$name]]  <- ix$result$model
    lambdas[[ix$name]] <- ix$result$lambda
    coefs[[ix$name]]   <- ix$result$coef
  }
   
  #
  # Kaplan-Meier (p.value)
  #
  
  #
  km.train <- list()
  km.test  <- list()
  #
  for (ix.name in names(coefs)) {
    km.train[[ix.name]] <- my.draw.kaplan(list(ix.name = coefs[[ix.name]]), filename = 'Train set')$pvalue
    km.test[[ix.name]]  <- my.draw.kaplan(list(ix.name = coefs[[ix.name]]), filename = 'Test set', test.set = T)$pvalue
  }
  
  #
  # C-INDEX
  # 
  
  #
  #
  # Train (c.index)
  #
  
  all.pairs <- combn(nrow(xdata.train), 2)
  c.index.train <- list()
  c.index.test  <- list()
  
  for (ix.name in names(coefs)) {
    c.index.train[[ix.name]] <- fit.risk(coefs[[ix.name]], xdata.train, ydata.train, ix.name,  show.message = FALSE)
  }
  
  #
  #
  # Test (c.index)
  #
  
  all.pairs <- combn(nrow(xdata.test), 2)

  for (ix.name in names(coefs)) {
    c.index.test[[ix.name]] <- fit.risk(coefs[[ix.name]], xdata.train, ydata.train, ix.name,  show.message = FALSE)
  }
  
  return(list(metrics = list(km.train      = km.train, 
                             km.test       = km.test,
                             c.index.train = c.index.train, 
                             c.index.test  = c.index.test),
              coefs = coefs))
}
```


```{r calc_ntimes, echo=FALSE, eval=FALSE}
if (params$train == 1) {
  flog.info("Train and test sets are the same, won't calculate %d times with random seeds", params$ntimes)
} else {
  set.seed(params$seed)
  seed.vec <- sample(1000 + (max(c(1:1e7,params$ntimes))))[1:params$ntimes]
  
  ntimes.results <- parallel::mclapply(seed.vec, function(seed) {
    return(run.cache(call.results,
                     seed, xdata, ydata, params$train, params$subset, 
                     penalty.factor.degree.new, 
                     penalty.factor.degree.old, 
                     penalty.factor.orphan,
                     #
                     cache.digest = list(NULL, xdata.digest.cache, ydata.digest.cache),
                     cache.prefix = 'big-diff'))
  #}, mc.cores = 1, mc.allow.recursive = FALSE)
  }, mc.cores = params$mc.cores, mc.allow.recursive = FALSE)
  
  #if (params$ntimes == 1) {
  #  ntimes.results <- list(ntimes.results)
  #}
  
  big.df <- data.frame()
  for (ix in seq_along(ntimes.results)) {
    el        <- ntimes.results[[ix]]$metrics
    for (ix.el in names(el)) {
      my.values <- sapply(names(el[[ix.el]]), function(ix.model) {el[[ix.el]][[ix.model]]})
      my.names  <- rep(ix.el, length(my.values))
      my.models <- names(el[[ix.el]])
      new.line  <- data.frame(metric = my.names, model = my.models, values = as.numeric(my.values), stringsAsFactors = FALSE)
      big.df    <- rbind(big.df, new.line)
    }
  }
  #big.df$model <- factor(big.df$model, levels = c('glmnet', 'degree', 'orphan'), labels = c('GLMNET', 'DegreeCox', 'OrphanCox'))
  big.df$metric <- factor(big.df$metric, levels = c('c.index.train', 'c.index.test', 'km.train', 'km.test'), 
                                                    labels = c('C-Index (Train set)', 'C-Index (Test set)', 'Log-rank (Train set)', 'Log-rank (Test set)'))
}
```

## C-Index distribution

```{r c.index.iter, echo=FALSE, fig.height=20}
ggplot(filter(big.df, metric %in% c('C-Index (Train set)', 'C-Index (Test set)'))) +
    geom_freqpoly(aes(values, color = model), alpha = .75, bins = 100) + 
    facet_wrap(model ~ metric, ncol = 2) +
    theme_minimal() + theme(legend.position = 'top')
```

## Log-rank test on Kaplan-Meier models

Separated by high and low risk groups

```{r pvalue.itre, echo=FALSE, fig.height=20}
ggplot(filter(big.df, metric %in% c('Log-rank (Test set)', 'Log-rank (Train set)'))) +
  geom_freqpoly(aes(values, color = model), alpha = .75, bins = 300) + 
  facet_wrap(model ~ metric, ncol = 2) +
  ggtitle('Distribution of Log-Rank up until 0.05') +
  theme_minimal() + theme(legend.position = 'top') + coord_cartesian(xlim = c(0, 0.1))

ggplot(filter(big.df, metric %in% c('Log-rank (Test set)', 'Log-rank (Train set)'))) +
  geom_freqpoly(aes(values, color = model), alpha = .75, bins = 100) + 
  facet_wrap(model ~ metric, ncol = 2) +
  ggtitle('Full distribution Log-rank') +
  theme_minimal() + theme(legend.position = 'top')
```


